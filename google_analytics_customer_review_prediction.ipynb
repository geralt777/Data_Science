{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#list of imports that will be required\nimport os\nimport sys\n\nimport datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas.io.json import json_normalize\nimport json\n\n%matplotlib inline\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#The following code is used to read the datasets and process nested JSON data and process them into separate columns\n#We can then parse all json fields and use the data as present in a flattened csv format as ususal\n#credits : https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields\n#The original data as it is contains 4 JSON fields, ie., 'device', 'geoNetwork', 'totals', 'trafficSource'\n\ndef load_df(csv_path='../input/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    #print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"612003a5eae84c38998084b26d044d08d5f3ed01"},"cell_type":"code","source":"#Load training data\ntrain_df = load_df(\"../input/train.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7099c09fe8d27bf1d2ca391db1a3cec0e32af91"},"cell_type":"code","source":"#change data types for columns with numerical values\ntrain_df[\"totals.bounces\"] = train_df[\"totals.bounces\"].astype('float')\ntrain_df[\"totals.hits\"] = train_df[\"totals.hits\"].astype('float')\ntrain_df[\"totals.newVisits\"] = train_df[\"totals.newVisits\"].astype('float')\ntrain_df[\"totals.pageviews\"] = train_df[\"totals.pageviews\"].astype('float')\ntrain_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype('float')\n\n#We can see that there are several columns that contain NaN values, it is better to assign numeric values to them\ntrain_df[\"totals.bounces\"].fillna(0, inplace=True)\ntrain_df[\"totals.hits\"].fillna(0, inplace=True)\ntrain_df[\"totals.newVisits\"].fillna(0, inplace=True)\ntrain_df[\"totals.pageviews\"].fillna(1, inplace=True)\ntrain_df[\"totals.transactionRevenue\"].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"203a65f013d0b0ea98f2cfd82659287c6798aaa0"},"cell_type":"code","source":"#DATA CLEANING\n\ndef clean_data(df):\n    \n    #On a cursory glance at the data, some columns have the value \"not available in demo dataset\". \n    #In cases where the columns contain only one type of value, we can safely drop these columns as they will not affect prediction\n    print(\"Shape of data before dropping columns: \", df.shape)\n    for col in df.columns:\n        if len(df[col].unique()) == 1:\n            df.drop(col,inplace=True,axis=1)\n    print(\"Shape of data after dropping columns: \", df.shape)\n    \n    #modifying date to date_time type\n    print(\"Now modifing date to date_time type\")\n    #df['date'] = df['date'].astype(str)\n    #df[\"date\"] = df[\"date\"].apply(lambda x : datetime.date(int((x)[:4]), int((x)[4:6]), int((x)[6:])))\n    df[\"date\"] = pd.to_datetime(df.date, format=\"%Y%m%d\")\n    \n    #lets drop the sessionId column, which is just a combination of fullVisitorId and visitId\n    df = df.drop('sessionId', axis=1)\n    \n    #I add a few columns for day, month, day of the week, and year, so we can see how they effect the transaction amounts\n    df[\"month\"] = df['date'].dt.month\n    df[\"year\"] = df['date'].dt.year\n    df[\"weekday\"] = df['date'].dt.weekday\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33a7285e071b3d3f1ae0cd568926a3feae3bbf15"},"cell_type":"code","source":"train_df = clean_data(train_df)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3437fcf03abfd52cd2799628537e73a22c91bb61"},"cell_type":"code","source":"#change data types for columns with numerical values\ntrain_df[\"totals.bounces\"] = train_df[\"totals.bounces\"].astype('float')\ntrain_df[\"totals.hits\"] = train_df[\"totals.hits\"].astype('float')\ntrain_df[\"totals.newVisits\"] = train_df[\"totals.newVisits\"].astype('float')\ntrain_df[\"totals.pageviews\"] = train_df[\"totals.pageviews\"].astype('float')\ntrain_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype('float')\n\n#We can see that there are several columns that contain NaN values, it is better to assign numeric values to them\ntrain_df[\"totals.bounces\"].fillna(0, inplace=True)\ntrain_df[\"totals.hits\"].fillna(0, inplace=True)\ntrain_df[\"totals.newVisits\"].fillna(0, inplace=True)\ntrain_df[\"totals.pageviews\"].fillna(1, inplace=True)\ntrain_df[\"totals.transactionRevenue\"].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b5990538ec2c8a42fbe6c506c17458eee6e70de"},"cell_type":"code","source":"#Looking at the data, there seem to be some cloumns still there that can be safely dropped\n#If any column has a large number of entries with missing values, we can drop them\npercent = (train_df.isnull().sum() / train_df.isnull().count() * 100 ).sort_values(ascending = False)\nprint (percent) # Returning values of nulls different of 0   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a919d5728761bb966820cb6b1859d05114a176a"},"cell_type":"code","source":"#looking at this, we see that the column with missing percentage greater than 99.99% can be safely dropped.\n#But other columns with a high missing percentage are still kept.\ntrain_df = train_df.drop('trafficSource.campaignCode', axis=1)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"373bc5d99dc9bb3b96cf8a6597b0695590943ba0"},"cell_type":"code","source":"train_df[\"totals.hits\"] =  (train_df['totals.hits'] - min(train_df['totals.hits'])) / (max(train_df['totals.hits'])  - min(train_df['totals.hits']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afbbe2a37632b1d190042406241e989e84f19131"},"cell_type":"code","source":"#Some visualization...\n#We can first look at the device columns and how they relate to the revenue\n#we plot figures of devices and the number of non-zero revenue amounts they have\n\nfig, axes = plt.subplots(3,2, figsize=(30,30))\ntrain_df['device.browser'].value_counts().head(12).plot(kind='bar', ax=axes[0][0], rot=25, legend='Device Browser', color='red')\n#train_df['device.browser'].value_counts().head(12).plot(kind='bar', ax=axes[0][1], rot=25, legend='Device Browser', color='red')\ntrain_df.groupby(['device.browser'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(10).plot(kind='bar', ax=axes[0][1], rot=25, legend='Device Browser', color='red')\ntrain_df['device.deviceCategory'].value_counts().head(10).plot(kind='bar', ax=axes[1][0], rot=25, legend='Device Browser', color='blue')\ntrain_df.groupby(['device.deviceCategory'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(10).plot(kind='bar', ax=axes[1][1], rot=25, legend='Device Browser', color='blue')\ntrain_df['device.operatingSystem'].value_counts().head(10).plot(kind='bar', ax=axes[2][0], rot=25, legend='Device Browser', color='green')\ntrain_df.groupby(['device.operatingSystem'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(10).plot(kind='bar', ax=axes[2][1], rot=25, legend='Device Browser', color='green')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa680ebca6f62056ea9000385c81541b0330d555"},"cell_type":"code","source":"fig, axes = plt.subplots(3,2, figsize=(30,30))\ntrain_df['month'].value_counts().head(12).plot(kind='bar', ax=axes[0][0], rot=25, legend='Device Browser', color='red')\n#train_df['device.browser'].value_counts().head(12).plot(kind='bar', ax=axes[0][1], rot=25, legend='Device Browser', color='red')\ntrain_df.groupby(['month'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(10).plot(kind='bar', ax=axes[0][1], rot=25, legend='Device Browser', color='red')\ntrain_df['year'].value_counts().head(10).plot(kind='bar', ax=axes[1][0], rot=25, legend='Device Browser', color='blue')\ntrain_df.groupby(['year'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(10).plot(kind='bar', ax=axes[1][1], rot=25, legend='Device Browser', color='blue')\ntrain_df['weekday'].value_counts().head(10).plot(kind='bar', ax=axes[2][0], rot=25, legend='Device Browser', color='green')\ntrain_df.groupby(['weekday'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(10).plot(kind='bar', ax=axes[2][1], rot=25, legend='Device Browser', color='green')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6853dcfe007d7101b9b5f61fe9bfd722a38957da"},"cell_type":"code","source":"fig, axes = plt.subplots(1,1, figsize=(10,10))\n#train_df[\"visitNumber\"] = train_df[\"visitNumber\"].astype('float')\ntrain_df['visitNumber'].value_counts().head(25).plot(kind='line', rot=25, legend='Device Browser', color='red')\n#train_df.groupby(['visitNumber'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(15).plot(kind='bar', ax=axes[0][1], rot=25, legend='Device Browser', color='green')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43657e6cea38fd0ccee1347f6acc5d873ec4c243"},"cell_type":"code","source":"fig, axes = plt.subplots(1,1, figsize=(10,10))\ntrain_df.groupby(['visitNumber'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(30).plot(kind='bar', rot=25, legend='Device Browser', color='green')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"758ff61a7a2df0ba893587daa18c28e49b0cf40b"},"cell_type":"code","source":"fig, axes = plt.subplots(2,2, figsize=(20,20))\ntrain_df['geoNetwork.continent'].value_counts().head(12).plot(kind='bar', ax=axes[0][0], rot=25, legend='Device Browser', color='red')\ntrain_df.groupby(['geoNetwork.continent'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(10).plot(kind='bar', ax=axes[0][1], rot=25, legend='Device Browser', color='red')\ntrain_df['geoNetwork.subContinent'].value_counts().head(10).plot(kind='bar', ax=axes[1][0], rot=25, legend='Device Browser', color='blue')\ntrain_df.groupby(['geoNetwork.subContinent'])['totals.transactionRevenue'].agg('sum').sort_values(ascending=False).head(10).plot(kind='bar', ax=axes[1][1], rot=25, legend='Device Browser', color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec20ff70b8d6929a67dbb94e3acb9ef0c1138f14"},"cell_type":"code","source":"#For the prediction of the top ten buyers, I add a new column to the training set, which simply checks, whether a user has made a purchase\ntrain_df['buy'] = np.where(train_df['totals.transactionRevenue']>0, 1, 0)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1040181ab6e6258abf9ec262c9540507d46834b1"},"cell_type":"code","source":"#Modeling the dataset\n#Before starting, we should first check whether the columns in the training and test sets are the same, with the exception of the transactionRevenue column\ntest_df = load_df(\"../input/test.csv\")\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c43cd522c9c0516849cceba4a6e5878b2957813"},"cell_type":"code","source":"test_df = clean_data(test_df)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c2052baab34f6101d2951ec727044dce5892ae5"},"cell_type":"code","source":"#change data types for columns with numerical values\ntest_df[\"totals.bounces\"] = test_df[\"totals.bounces\"].astype('float')\ntest_df[\"totals.hits\"] = test_df[\"totals.hits\"].astype('float')\ntest_df[\"totals.newVisits\"] = test_df[\"totals.newVisits\"].astype('float')\ntest_df[\"totals.pageviews\"] = test_df[\"totals.pageviews\"].astype('float')\n\n#We can see that there are several columns that contain NaN values, it is better to assign numeric values to them\ntest_df[\"totals.bounces\"].fillna(0, inplace=True)\ntest_df[\"totals.hits\"].fillna(0, inplace=True)\ntest_df[\"totals.newVisits\"].fillna(0, inplace=True)\ntest_df[\"totals.pageviews\"].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d916afa88011786b780250fd2d9d525abf0997e"},"cell_type":"code","source":"print(\"Variables not in test but in train : \", set(train_df.columns).difference(set(test_df.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"043b1b9ffa0b42074302b30ba7cb3854c209a161"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n#handle categorical columns\ncat_cols = ['channelGrouping', 'device.browser', 'device.deviceCategory', 'device.operatingSystem',\n            'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country', 'geoNetwork.metro',\n            'geoNetwork.networkDomain', 'geoNetwork.region', 'geoNetwork.subContinent', 'trafficSource.adContent', \n            'trafficSource.adwordsClickInfo.adNetworkType', 'trafficSource.adwordsClickInfo.gclId', 'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.adwordsClickInfo.page', \n            'trafficSource.adwordsClickInfo.slot', 'trafficSource.campaign', 'trafficSource.isTrueDirect', 'trafficSource.keyword', 'trafficSource.medium', \n            'trafficSource.referralPath', 'trafficSource.source']\nfor c in cat_cols:\n    lbl_enc = LabelEncoder()\n    train_vals = list(train_df[c].values.astype(str))\n    test_vals = list(test_df[c].values.astype(str))\n    lbl_enc.fit(train_vals + test_vals)\n    train_df[c] = lbl_enc.transform(train_vals)\n    test_df[c] = lbl_enc.transform(test_vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c9dee0edd96e47c83d13e7da176453ad2f00a7b"},"cell_type":"code","source":"train_df[\"totals.pageviews\"] =  (train_df['totals.pageviews'] - min(train_df['totals.pageviews'])) / (max(train_df['totals.pageviews'])  - min(train_df['totals.pageviews']))\ntest_df[\"totals.hits\"] =  (test_df['totals.hits'] - min(test_df['totals.hits'])) / (max(test_df['totals.hits'])  - min(test_df['totals.hits']))\ntest_df[\"totals.pageviews\"] =  (test_df['totals.pageviews'] - min(test_df['totals.pageviews'])) / (max(test_df['totals.pageviews'])  - min(test_df['totals.pageviews']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f89a6095b2cb7811704745396bf9e42c23b1b95"},"cell_type":"code","source":"#https://github.com/Microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py\nimport lightgbm as lgb\n# specify your configurations as a dict\nparams = {\n    'task': 'train',\n    'objective': 'regression',\n    'metric': 'rmse',\n    'num_leaves': 40,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.6,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 5\n}\n\nfeature_cols = ['channelGrouping', 'device.browser', 'device.deviceCategory', 'device.operatingSystem',\n            'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country', 'geoNetwork.metro',\n            'geoNetwork.networkDomain', 'geoNetwork.region', 'geoNetwork.subContinent', 'trafficSource.adContent', \n            'trafficSource.adwordsClickInfo.adNetworkType', 'trafficSource.adwordsClickInfo.gclId', 'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.adwordsClickInfo.page', \n            'trafficSource.adwordsClickInfo.slot', 'trafficSource.campaign', 'trafficSource.isTrueDirect', 'trafficSource.keyword', 'trafficSource.medium', \n            'trafficSource.referralPath', 'trafficSource.source', 'totals.bounces', 'totals.hits', 'totals.newVisits', 'totals.pageviews']\n\ntemp=train_df[\"totals.transactionRevenue\"]\ntrain_df[\"totals.transactionRevenue\"] = np.log1p(train_df[\"totals.transactionRevenue\"].astype(float))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9eb5e564af219450aa07c2210cf6da7d747787dc"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\ntrain_x, val_x, train_y, val_y = train_test_split(train_df[feature_cols], train_df['totals.transactionRevenue'], train_size=0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74b3f9373ad6c1a8587b9936d8dd55edec8af5ef"},"cell_type":"code","source":"lgbmtrain = lgb.Dataset(train_x, label=train_y)\nlgbmval = lgb.Dataset(val_x, label=val_y)\nmodel = lgb.train(params, lgbmtrain, 1000, valid_sets=[lgbmval], early_stopping_rounds=50, verbose_eval=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30024881d7b42b1149acd21474b299f79640583c"},"cell_type":"code","source":"sub_df = pd.DataFrame({\"fullVisitorId\":test_df.fullVisitorId})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a09bcd41958b028b628b3debf7552d66f41e49c"},"cell_type":"code","source":"from sklearn import metrics\n\npred = model.predict(test_df[feature_cols], num_iteration=model.best_iteration)\ntest_df[\"PredictedLogRevenue\"] = np.expm1(pred)\nsub_df = test_df.groupby(\"fullVisitorId\").agg({\"PredictedLogRevenue\" : \"sum\"}).reset_index()\nsub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])\nsub_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3919705bc2880702b24f07303e8198a75a4d12b"},"cell_type":"code","source":"#we cannot have negative values, so we make them 0\nsub_df['PredictedLogRevenue'] = sub_df['PredictedLogRevenue'].apply(lambda x: 0 if x<0 else x)\nsub_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7c91b926303d29c556645f79caec84d3c7c20c2"},"cell_type":"code","source":"sub_df.to_csv(\"final_result.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}