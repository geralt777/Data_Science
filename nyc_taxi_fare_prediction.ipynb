{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#load python modules that might be needed\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#load the training data (as much as needed)\n",
    "data_train = pd.read_csv('../input/train.csv', nrows = 10000000)\n",
    "#data_train.describe()\n",
    "\n",
    "#load the test data\n",
    "data_test = pd.read_csv('../input/test.csv')\n",
    "#data_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32227c04728d446d83f76893ad2cded00e3ea6bb"
   },
   "outputs": [],
   "source": [
    "#....CLEANING THE DATA....#\n",
    "# - using the 'describe' method, a few anomalies were observed\n",
    "# - minimum value of the fare was negative, which is absurd, so these entries were removed\n",
    "# - minimum passenger count was 0, which again, doesn't make any sense, and corresponding entries were removed\n",
    "# - in case of 0 passeneger count, it probably was an erroneous entry or the taxi could have just been transporting goods but seeing as how there are no such entries in the test data, it was simpler to just discard those entries\n",
    "# - finally, looking at the test data, I set the bounds of the number of passengers to 1 and 6\n",
    "# - latitude and longitudinal entries were out of bounds, so I observed the test data to obtain a set of limits for the entries\n",
    "# - Using the info, entries with positional data out of the limits were removed\n",
    "# - Also, rows with missing entries were removed\n",
    "\n",
    "#remove missing rows\n",
    "print('Missing entries removal')\n",
    "print('Old size: %d' % len(data_train))\n",
    "data_train = data_train.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ffa5268c1f0e6348e346f276a8c251c7e87ea3c"
   },
   "outputs": [],
   "source": [
    "#remove entries with negative fare or fare greater than $350(intercity fares are not going to be as high and are treated as outliers)\n",
    "print('Negative fares removal')\n",
    "print('Old size: %d' % len(data_train))\n",
    "data_train = data_train[(data_train.fare_amount>=0) & (data_train.fare_amount<350)]\n",
    "print('New size: %d' % len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cdeba1315b3382a3fbdce8d7fee0634e109aee6c"
   },
   "outputs": [],
   "source": [
    "#remove entries with passenger count below 1 and above 6\n",
    "print('Passenger Count Check')\n",
    "print('Old size: %d' % len(data_train))\n",
    "data_train = data_train[(data_train.passenger_count>0) & (data_train.passenger_count<7)]\n",
    "print('New size: %d' % len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "020f28b6f3cccbee7ab9efdd7ed70049c02c22f2"
   },
   "outputs": [],
   "source": [
    "#remove entries with positional data outside the defined bounding box(as obtained from the test set)\n",
    "min_longitude = min(data_test.pickup_longitude.min(), data_test.dropoff_longitude.min())\n",
    "min_latitude = min(data_test.pickup_latitude.min(), data_test.dropoff_latitude.min())\n",
    "max_longitude = max(data_test.pickup_longitude.max(), data_test.dropoff_longitude.max())\n",
    "max_latitude = max(data_test.pickup_latitude.max(), data_test.dropoff_latitude.max())\n",
    "\n",
    "print('Positional Check')\n",
    "print('Old size: %d' % len(data_train))\n",
    "data_train = data_train[(data_train.pickup_longitude >= min_longitude) & (data_train.pickup_longitude <= max_longitude) & \\\n",
    "                        (data_train.dropoff_longitude >= min_longitude) & (data_train.dropoff_longitude <= max_longitude) & \\\n",
    "                        (data_train.pickup_latitude >= min_latitude) & (data_train.pickup_latitude <= max_latitude) & \\\n",
    "                        (data_train.dropoff_latitude >= min_latitude) & (data_train.dropoff_latitude <= max_latitude)]\n",
    "print('New size: %d' % len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "564429a39139158569ddf6377d1988c968801ed1"
   },
   "outputs": [],
   "source": [
    "#Calculation of Pearson correlation\n",
    "\n",
    "#Haversine distance formula\n",
    "#this was obtained from 'https://stackoverflow.com/questions/27928/calculate-distance-between-two-latitude-longitude-points-haversine-formula'\n",
    "def hav_distance(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295 # Pi/180\n",
    "    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n",
    "    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...\n",
    "\n",
    "#create a new column for the euclidean distance based on the haversine distance formula\n",
    "data_train['distance_miles'] = hav_distance(data_train.pickup_latitude, data_train.pickup_longitude, data_train.dropoff_latitude, data_train.dropoff_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "343ce37f55a21b3c6bbbe5fe66f46d60a23ac7ed"
   },
   "outputs": [],
   "source": [
    "#corr1 = data_train['distance_miles'].corr(data_train['fare_amount'])\n",
    "corr1 = data_train['fare_amount'].corr(data_train['distance_miles'])\n",
    "print(corr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d049e93e7a38eb72a109f1c3b5e34cfa47555a3e"
   },
   "outputs": [],
   "source": [
    "#I now transform the given date/time to a form that is much easier to work with (for obtaining hours, minutes, etc.)\n",
    "data_train['pickup_datetime'] = pd.to_datetime(data_train['pickup_datetime'], format='%Y-%m-%d  %H:%M:%S %Z')\n",
    "\n",
    "#A new column that contains the time of the day (only hour of the day is sufficient) is now added to the training data\n",
    "data_train['time'] = (data_train['pickup_datetime'].dt.hour * 60) + data_train['pickup_datetime'].dt.minute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9e0c92271f72af302854145d1b624fa5cc7d594"
   },
   "outputs": [],
   "source": [
    "corr2 = data_train['time'].corr(data_train['distance_miles'])\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c9f1bb24f0f4cee5fcf48133176b051cd82e5b3"
   },
   "outputs": [],
   "source": [
    "corr3 = data_train['time'].corr(data_train['fare_amount'])\n",
    "print(corr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a91e834337c93cd423b92799057192034dac2bb6"
   },
   "outputs": [],
   "source": [
    "data_train.plot.scatter(x=\"distance_miles\", y=\"fare_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1db68626a594dcd8dd5285a86b2ea7a85e087302"
   },
   "outputs": [],
   "source": [
    "data_train.plot.scatter(x=\"time\", y=\"distance_miles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f5e5443f73fe2eef6b36a5d414a842d6802e6ce"
   },
   "outputs": [],
   "source": [
    "data_train.plot.scatter(x=\"time\", y=\"fare_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18148fc1da62279ac962228161fc7bdcd9ffcbd3"
   },
   "outputs": [],
   "source": [
    "long_range = (-74.03, -73.75)\n",
    "lat_range = (40.63, 40.85)\n",
    "data_train.plot.scatter(x=\"pickup_longitude\", y=\"pickup_latitude\", s=0.03, alpha = 0.5, color='g')\n",
    "plt.ylim(lat_range)\n",
    "plt.xlim(long_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b09e6dbf9561fe9a3286ede7d849a1ad3abcf436"
   },
   "outputs": [],
   "source": [
    "data_train.plot.scatter(x=\"dropoff_longitude\", y=\"dropoff_latitude\", s=0.03, alpha = 0.5, color='r')\n",
    "plt.ylim(lat_range)\n",
    "plt.xlim(long_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a348f987f1534390fa5154d2ac5412f86365f6d3"
   },
   "outputs": [],
   "source": [
    "data_train['week_day'] = data_train['pickup_datetime'].dt.weekday\n",
    "#data_train.week_day.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc2a16c0f2601d06cc88f43266ea15fe6e2ce7ba"
   },
   "outputs": [],
   "source": [
    "data_train['year'] = data_train['pickup_datetime'].dt.year\n",
    "#data_train.year.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d40f4f05c99f7c4b72d51a0caf220395f498dc35"
   },
   "outputs": [],
   "source": [
    "data_train['month'] = data_train['pickup_datetime'].dt.month\n",
    "#data_train.month.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79e60aef6f6f435ef380ce3ca10d1759820ee397"
   },
   "outputs": [],
   "source": [
    "nyc_center = (-74.006, 40.712)\n",
    "data_train['pick_dist_cent'] = hav_distance(nyc_center[1], nyc_center[0], data_train.pickup_latitude, data_train.pickup_longitude)\n",
    "data_train['drop_dist_cent'] = hav_distance(nyc_center[1], nyc_center[0], data_train.dropoff_latitude, data_train.dropoff_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f6f4e21ea7a6e662cb4ad5053525124706b3990"
   },
   "outputs": [],
   "source": [
    "#simple linear regression\n",
    "feature_list = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'distance_miles', 'passenger_count']\n",
    "x = data_train[feature_list].values\n",
    "y = data_train['fare_amount'].values\n",
    "data_test['distance_miles'] = hav_distance(data_test.pickup_latitude, data_test.pickup_longitude, data_test.dropoff_latitude, data_test.dropoff_longitude)\n",
    "x_test = data_test[feature_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2ee18d0f71dd186228c7d1844da10686f773f19"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(x)\n",
    "rescaledX = scaler.transform(x)\n",
    "scaler = StandardScaler().fit(x_test)\n",
    "rescaledX_test = scaler.transform(x_test)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(rescaledX, y)\n",
    "print(regr.coef_)\n",
    "y_test_pred = regr.predict(rescaledX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c10ca04e88b55ec7289184b0e6a852d618ba047e"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'key': data_test.key, 'fare_amount': y_test_pred},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8049f1b7ba332ec74bb2dde629eacd33b559211d"
   },
   "outputs": [],
   "source": [
    "'''from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors=4)\n",
    "neigh.fit(rescaledX, y)\n",
    "y_test_pred_knr = neigh.predict(rescaledX_test)\n",
    "print('Done')'''\n",
    "\n",
    "'''from sklearn.neighbors import RandomForestRegressor\n",
    "\n",
    "neigh = RandomForestRegressor(n_estimators=10, max_depth=10, min_samples_leaf=10)\n",
    "neigh.fit(rescaledX, y)\n",
    "y_test_pred_random = neigh.predict(rescaledX_test)\n",
    "print('Done')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
